// AUTO-GENERATED FILE. DO NOT MODIFY.
// This file is auto-generated by the Ballerina OpenAPI tool.

// Copyright (c) 2024, WSO2 LLC. (http://www.wso2.com).
//
// WSO2 LLC. licenses this file to you under the Apache License,
// Version 2.0 (the "License"); you may not use this file except
// in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

import ballerina/constraint;
import ballerina/data.jsondata;
import ballerina/http;

# The request counts for different statuses within the batch
public type BatchRequestCounts record {
    # Total number of requests in the batch
    int total;
    # Number of requests that have been completed successfully
    int completed;
    # Number of requests that have failed
    int failed;
};

# The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use
public type FineTuningJobCheckpoint record {
    # The step number that the checkpoint was created at
    @jsondata:Name {value: "step_number"}
    int stepNumber;
    # The Unix timestamp (in seconds) for when the checkpoint was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The name of the fine-tuning job that this checkpoint was created from
    @jsondata:Name {value: "fine_tuning_job_id"}
    string fineTuningJobId;
    # The checkpoint identifier, which can be referenced in the API endpoints
    string id;
    FineTuningJobCheckpointMetrics metrics;
    # The name of the fine-tuned checkpoint model that is created
    @jsondata:Name {value: "fine_tuned_model_checkpoint"}
    string fineTunedModelCheckpoint;
    # The object type, which is always "fine_tuning.job.checkpoint"
    "fine_tuning.job.checkpoint" 'object;
};

# Represents the Headers record for the operation: listMessages
public type ListMessagesHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# `none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user
public type AssistantsApiToolChoiceOptionOneOf1 "none"|"auto"|"required";

public type ListRunsResponse record {
    @jsondata:Name {value: "first_id"}
    string firstId;
    RunObject[] data;
    @jsondata:Name {value: "last_id"}
    string lastId;
    @jsondata:Name {value: "has_more"}
    boolean hasMore;
    string 'object;
};

# Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models/gpt-4o), [GPT-4 Turbo](/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.
# 
# Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.
# 
# **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length
public type AssistantsApiResponseFormatOption AssistantsApiResponseFormatOptionOneOf1|AssistantsApiResponseFormat;

public type RunStepDetailsToolCallsFunctionObject record {
    RunStepDetailsToolCallsFunctionObjectFunction 'function;
    # The ID of the tool call object
    string id;
    # The type of tool call. This is always going to be `function` for this type of tool call
    "function" 'type;
};

public type CreateRunRequest record {|
    # Overrides the [instructions](/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis
    string? instructions?;
    # Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions
    @jsondata:Name {value: "additional_instructions"}
    string? additionalInstructions?;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    # The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run
    @jsondata:Name {value: "assistant_id"}
    string assistantId;
    # Adds additional messages to the thread before creating the run
    @jsondata:Name {value: "additional_messages"}
    CreateMessageRequest[]? additionalMessages?;
    # Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis
    AssistantObjectTools[]? tools?;
    @jsondata:Name {value: "truncation_strategy"}
    TruncationObject truncationStrategy?;
    # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
    # 
    # We generally recommend altering this or temperature but not both
    @jsondata:Name {value: "top_p"}
    decimal? topP = 1;
    # The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
    @jsondata:Name {value: "max_completion_tokens"}
    int? maxCompletionTokens?;
    @jsondata:Name {value: "response_format"}
    AssistantsApiResponseFormatOption responseFormat?;
    @jsondata:Name {value: "parallel_tool_calls"}
    ParallelToolCalls parallelToolCalls?;
    # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
    decimal? temperature = 1;
    @jsondata:Name {value: "tool_choice"}
    AssistantsApiToolChoiceOption toolChoice?;
    # The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used
    string|"gpt-4o"|"gpt-4o-2024-05-13"|"gpt-4o-mini"|"gpt-4o-mini-2024-07-18"|"gpt-4-turbo"|"gpt-4-turbo-2024-04-09"|"gpt-4-0125-preview"|"gpt-4-turbo-preview"|"gpt-4-1106-preview"|"gpt-4-vision-preview"|"gpt-4"|"gpt-4-0314"|"gpt-4-0613"|"gpt-4-32k"|"gpt-4-32k-0314"|"gpt-4-32k-0613"|"gpt-3.5-turbo"|"gpt-3.5-turbo-16k"|"gpt-3.5-turbo-0613"|"gpt-3.5-turbo-1106"|"gpt-3.5-turbo-0125"|"gpt-3.5-turbo-16k-0613"? model?;
    # The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
    @jsondata:Name {value: "max_prompt_tokens"}
    int? maxPromptTokens?;
|};

public type InputItemsArray int[];

public type ListFineTuningJobCheckpointsResponse record {
    @jsondata:Name {value: "first_id"}
    string? firstId?;
    FineTuningJobCheckpoint[] data;
    @jsondata:Name {value: "last_id"}
    string? lastId?;
    @jsondata:Name {value: "has_more"}
    boolean hasMore;
    "list" 'object;
};

# Represents the Headers record for the operation: deleteMessage
public type DeleteMessageHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# Controls which (if any) tool is called by the model.
# `none` means the model will not call any tool and instead generates a message.
# `auto` means the model can pick between generating a message or calling one or more tools.
# `required` means the model must call one or more tools.
# Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
# 
# `none` is the default when no tools are present. `auto` is the default if tools are present
public type ChatCompletionToolChoiceOption ChatCompletionToolChoiceOptionOneOf1|ChatCompletionNamedToolChoice;

# Details on the action required to continue the run. Will be `null` if no action is required
public type RunObjectRequiredAction record {
    @jsondata:Name {value: "submit_tool_outputs"}
    RunObjectRequiredActionSubmitToolOutputs submitToolOutputs;
    # For now, this is always `submit_tool_outputs`
    "submit_tool_outputs" 'type;
};

# The default strategy. This strategy currently uses a `max_chunk_size_tokens` of `800` and `chunk_overlap_tokens` of `400`
public type AutoChunkingStrategyRequestParam record {|
    # Always `auto`
    "auto" 'type;
|};

# Provides a set of configurations for controlling the behaviours when communicating with a remote HTTP endpoint.
@display {label: "Connection Config"}
public type ConnectionConfig record {|
    # Configurations related to client authentication
    http:BearerTokenConfig auth;
    # The HTTP version understood by the client
    http:HttpVersion httpVersion = http:HTTP_2_0;
    # Configurations related to HTTP/1.x protocol
    http:ClientHttp1Settings http1Settings = {};
    # Configurations related to HTTP/2 protocol
    http:ClientHttp2Settings http2Settings = {};
    # The maximum time to wait (in seconds) for a response before closing the connection
    decimal timeout = 30;
    # The choice of setting `forwarded`/`x-forwarded` header
    string forwarded = "disable";
    # Configurations associated with Redirection
    http:FollowRedirects followRedirects?;
    # Configurations associated with request pooling
    http:PoolConfiguration poolConfig?;
    # HTTP caching related configurations
    http:CacheConfig cache = {};
    # Specifies the way of handling compression (`accept-encoding`) header
    http:Compression compression = http:COMPRESSION_AUTO;
    # Configurations associated with the behaviour of the Circuit Breaker
    http:CircuitBreakerConfig circuitBreaker?;
    # Configurations associated with retrying
    http:RetryConfig retryConfig?;
    # Configurations associated with cookies
    http:CookieConfig cookieConfig?;
    # Configurations associated with inbound response size limits
    http:ResponseLimitConfigs responseLimits = {};
    # SSL/TLS-related options
    http:ClientSecureSocket secureSocket?;
    # Proxy server related options
    http:ProxyConfig proxy?;
    # Provides settings related to client socket configuration
    http:ClientSocketConfig socketConfig = {};
    # Enables the inbound payload validation functionality which provided by the constraint package. Enabled by default
    boolean validation = true;
    # Enables relaxed data binding on the client side. When enabled, `nil` values are treated as optional, 
    # and absent fields are handled as `nilable` types. Enabled by default.
    boolean laxDataBinding = true;
|};

# Represents the Headers record for the operation: submitToolOuputsToRun
public type SubmitToolOuputsToRunHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type AssistantToolsFileSearchTypeOnly record {
    # The type of tool being defined: `file_search`
    "file_search" 'type;
};

# Represents the Headers record for the operation: createThread
public type CreateThreadHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type AssistantToolsFileSearch record {
    @jsondata:Name {value: "file_search"}
    AssistantToolsFileSearchFileSearch fileSearch?;
    # The type of tool being defined: `file_search`
    "file_search" 'type;
};

# The tool calls generated by the model, such as function calls
public type ChatCompletionMessageToolCalls ChatCompletionMessageToolCall[];

public type CreateEmbeddingRequest record {|
    # Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens
    string|string[]|int[]|InputItemsArray[] input;
    # The format to return the embeddings in. Can be either `float` or [`base64`](https://pypi.org/project/pybase64/)
    @jsondata:Name {value: "encoding_format"}
    "float"|"base64" encodingFormat = "float";
    # ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
    string|"text-embedding-ada-002"|"text-embedding-3-small"|"text-embedding-3-large" model;
    # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
    string user?;
    # The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models
    @constraint:Int {minValue: 1}
    int dimensions?;
|};

# Represents the Headers record for the operation: createMessage
public type CreateMessageHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# Represents the Queries record for the operation: listVectorStoreFiles
public type ListVectorStoreFilesQueries record {
    # Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`
    "in_progress"|"completed"|"failed"|"cancelled" filter?;
    # A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
    string before?;
    # A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
    int 'limit = 20;
    # A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
    string after?;
    # Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
    "asc"|"desc" 'order = "desc";
};

public type ChatCompletionTokenLogprobTopLogprobs record {
    # The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely
    decimal logprob;
    # A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token
    int[]? bytes;
    # The token
    string token;
};

# Whether to enable [parallel function calling](/docs/guides/function-calling/parallel-function-calling) during tool use
public type ParallelToolCalls boolean;

public type CreateModerationRequest record {
    # The input text to classify
    string|string[] input;
    # Two content moderations models are available: `text-moderation-stable` and `text-moderation-latest`.
    # 
    # The default is `text-moderation-latest` which will be automatically upgraded over time. This ensures you are always using our most accurate model. If you use `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`
    string|"text-moderation-latest"|"text-moderation-stable" model = "text-moderation-latest";
};

public type CreateUploadRequest record {|
    # The name of the file to upload
    string filename;
    # The intended purpose of the uploaded file.
    # 
    # See the [documentation on File purposes](/docs/api-reference/files/create#files-create-purpose)
    "assistants"|"batch"|"fine-tune"|"vision" purpose;
    # The MIME type of the file.
    # 
    # This must fall within the supported MIME types for your file purpose. See the supported MIME types for assistants and vision
    @jsondata:Name {value: "mime_type"}
    string mimeType;
    # The number of bytes in the file you are uploading
    int bytes;
|};

public type TranscriptionWord record {
    # Start time of the word in seconds
    float 'start;
    # End time of the word in seconds
    float end;
    # The text content of the word
    string word;
};

# Represents the Headers record for the operation: modifyMessage
public type ModifyMessageHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type CreateSpeechRequest record {|
    # The voice to use when generating the audio. Supported voices are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech/voice-options)
    "alloy"|"echo"|"fable"|"onyx"|"nova"|"shimmer" voice;
    # The text to generate audio for. The maximum length is 4096 characters
    @constraint:String {maxLength: 4096}
    string input;
    # The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`, `wav`, and `pcm`
    @jsondata:Name {value: "response_format"}
    "mp3"|"opus"|"aac"|"flac"|"wav"|"pcm" responseFormat = "mp3";
    # One of the available [TTS models](/docs/models/tts): `tts-1` or `tts-1-hd`
    string|"tts-1"|"tts-1-hd" model;
    # The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is the default
    @constraint:Number {minValue: 0.25, maxValue: 4.0}
    decimal speed = 1.0;
|};

# A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
public type AssistantObjectToolResources record {
    @jsondata:Name {value: "code_interpreter"}
    AssistantObjectToolResourcesCodeInterpreter codeInterpreter?;
    @jsondata:Name {value: "file_search"}
    AssistantObjectToolResourcesFileSearch fileSearch?;
};

public type CreateVectorStoreFileRequest record {|
    @jsondata:Name {value: "chunking_strategy"}
    ChunkingStrategyRequestParam chunkingStrategy?;
    # A [File](/docs/api-reference/files) ID that the vector store should use. Useful for tools like `file_search` that can access files
    @jsondata:Name {value: "file_id"}
    string fileId;
|};

public type ChatCompletionRequestMessageContentPartText record {
    # The text content
    string text;
    # The type of the content part
    "text" 'type;
};

public type ModifyThreadRequest record {|
    @jsondata:Name {value: "tool_resources"}
    ThreadObjectToolResources? toolResources?;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
|};

# The text content that is part of a message
public type MessageContentTextObject record {
    MessageContentTextObjectText text;
    # Always `text`
    "text" 'type;
};

public type DeleteMessageResponse record {
    boolean deleted;
    string id;
    "thread.message.deleted" 'object;
};

# Represents the Headers record for the operation: listRunSteps
public type ListRunStepsHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# Represents the Queries record for the operation: listMessages
public type ListMessagesQueries record {
    # Filter messages by the run ID that generated them
    @http:Query {name: "run_id"}
    string runId?;
    # A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
    string before?;
    # A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
    int 'limit = 20;
    # A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
    string after?;
    # Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
    "asc"|"desc" 'order = "desc";
};

# Represents an embedding vector returned by embedding endpoint
public type Embedding record {
    # The index of the embedding in the list of embeddings
    int index;
    # The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings)
    decimal[] embedding;
    # The object type, which is always "embedding"
    "embedding" 'object;
};

# Represents the Queries record for the operation: listFineTuningEvents
public type ListFineTuningEventsQueries record {
    # Number of events to retrieve
    int 'limit = 20;
    # Identifier for the last event from the previous pagination request
    string after?;
};

public type RunStepDetailsMessageCreationObjectMessageCreation record {
    # The ID of the message that was created by this run step
    @jsondata:Name {value: "message_id"}
    string messageId;
};

public type CreateChatCompletionRequest record {
    # An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. `logprobs` must be set to `true` if this parameter is used
    @jsondata:Name {value: "top_logprobs"}
    int? topLogprobs?;
    # Modify the likelihood of specified tokens appearing in the completion.
    # 
    # Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token
    @jsondata:Name {value: "logit_bias"}
    record {|int...;|}? logitBias = {};
    # This feature is in Beta.
    # If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
    # Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend
    int? seed?;
    # Deprecated in favor of `tools`.
    # 
    # A list of functions the model may generate JSON inputs for
    # 
    # # Deprecated
    @constraint:Array {maxLength: 128, minLength: 1}
    @deprecated
    ChatCompletionFunctions[] functions?;
    # The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.
    # 
    # The total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens
    @jsondata:Name {value: "max_tokens"}
    int? maxTokens?;
    # Deprecated in favor of `tool_choice`.
    # 
    # Controls which (if any) function is called by the model.
    # `none` means the model will not call a function and instead generates a message.
    # `auto` means the model can pick between generating a message or calling a function.
    # Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.
    # 
    # `none` is the default when no functions are present. `auto` is the default if functions are present
    # 
    # # Deprecated
    @jsondata:Name {value: "function_call"}
    @deprecated
    "none"|"auto"|ChatCompletionFunctionCallOption functionCall?;
    # Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
    # 
    # [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
    @jsondata:Name {value: "presence_penalty"}
    decimal? presencePenalty = 0;
    # A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported
    ChatCompletionTool[] tools?;
    # How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep `n` as `1` to minimize costs
    int? n = 1;
    # Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the `content` of `message`
    boolean? logprobs = false;
    # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
    # 
    # We generally recommend altering this or `temperature` but not both
    @jsondata:Name {value: "top_p"}
    decimal? topP = 1;
    # Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
    # 
    # [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
    @jsondata:Name {value: "frequency_penalty"}
    decimal? frequencyPenalty = 0;
    @jsondata:Name {value: "response_format"}
    CreateChatCompletionRequestResponseFormat responseFormat?;
    # Up to 4 sequences where the API will stop generating further tokens
    string|string[]? stop = ();
    @jsondata:Name {value: "parallel_tool_calls"}
    ParallelToolCalls parallelToolCalls?;
    # If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions)
    boolean? 'stream = false;
    # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
    # 
    # We generally recommend altering this or `top_p` but not both
    decimal? temperature = 1;
    # A list of messages comprising the conversation so far. [Example Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models)
    @constraint:Array {minLength: 1}
    ChatCompletionRequestMessage[] messages;
    @jsondata:Name {value: "tool_choice"}
    ChatCompletionToolChoiceOption toolChoice?;
    # ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility) table for details on which models work with the Chat API
    string|"gpt-4o"|"gpt-4o-2024-05-13"|"gpt-4o-mini"|"gpt-4o-mini-2024-07-18"|"gpt-4-turbo"|"gpt-4-turbo-2024-04-09"|"gpt-4-0125-preview"|"gpt-4-turbo-preview"|"gpt-4-1106-preview"|"gpt-4-vision-preview"|"gpt-4"|"gpt-4-0314"|"gpt-4-0613"|"gpt-4-32k"|"gpt-4-32k-0314"|"gpt-4-32k-0613"|"gpt-3.5-turbo"|"gpt-3.5-turbo-16k"|"gpt-3.5-turbo-0301"|"gpt-3.5-turbo-0613"|"gpt-3.5-turbo-1106"|"gpt-3.5-turbo-0125"|"gpt-3.5-turbo-16k-0613" model;
    # Specifies the latency tier to use for processing the request. This parameter is relevant for customers subscribed to the scale tier service:
    #   - If set to 'auto', the system will utilize scale tier credits until they are exhausted.
    #   - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
    #   - When not set, the default behavior is 'auto'.
    # 
    #   When this parameter is set, the response body will include the `service_tier` utilized
    @jsondata:Name {value: "service_tier"}
    "auto"|"default"? serviceTier?;
    @jsondata:Name {value: "stream_options"}
    ChatCompletionStreamOptions? streamOptions?;
    # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
    string user?;
};

# A list of the categories, and whether they are flagged or not
public type CreateModerationResponseCategories record {
    # Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders
    @jsondata:Name {value: "self-harm/intent"}
    boolean selfHarmIntent;
    # Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste
    @jsondata:Name {value: "hate/threatening"}
    boolean hateThreatening;
    # Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts
    @jsondata:Name {value: "self-harm/instructions"}
    boolean selfHarmInstructions;
    # Sexual content that includes an individual who is under 18 years old
    @jsondata:Name {value: "sexual/minors"}
    boolean sexualMinors;
    # Harassment content that also includes violence or serious harm towards any target
    @jsondata:Name {value: "harassment/threatening"}
    boolean harassmentThreatening;
    # Content that expresses, incites, or promotes hate based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste. Hateful content aimed at non-protected groups (e.g., chess players) is harassment
    boolean hate;
    # Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders
    @jsondata:Name {value: "self-harm"}
    boolean selfHarm;
    # Content that expresses, incites, or promotes harassing language towards any target
    boolean harassment;
    # Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness)
    boolean sexual;
    # Content that depicts death, violence, or physical injury in graphic detail
    @jsondata:Name {value: "violence/graphic"}
    boolean violenceGraphic;
    # Content that depicts death, violence, or physical injury
    boolean violence;
};

# A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
public type ModifyAssistantRequestToolResources record {
    @jsondata:Name {value: "code_interpreter"}
    ModifyAssistantRequestToolResourcesCodeInterpreter codeInterpreter?;
    @jsondata:Name {value: "file_search"}
    ModifyAssistantRequestToolResourcesFileSearch fileSearch?;
};

# Usage statistics for the completion request
public type CompletionUsage record {
    # Number of tokens in the generated completion
    @jsondata:Name {value: "completion_tokens"}
    int completionTokens;
    # Number of tokens in the prompt
    @jsondata:Name {value: "prompt_tokens"}
    int promptTokens;
    # Total number of tokens used in the request (prompt + completion)
    @jsondata:Name {value: "total_tokens"}
    int totalTokens;
};

# Tool call objects
public type RunToolCallObject record {
    RunToolCallObjectFunction 'function;
    # The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs) endpoint
    string id;
    # The type of tool call the output is required for. For now, this is always `function`
    "function" 'type;
};

# Details of the tool call
public type RunStepDetailsToolCallsObject record {
    # An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`
    @jsondata:Name {value: "tool_calls"}
    RunStepDetailsToolCallsObjectToolCalls[] toolCalls;
    # Always `tool_calls`
    "tool_calls" 'type;
};

# A vector store is a collection of processed files can be used by the `file_search` tool
public type VectorStoreObject record {
    @jsondata:Name {value: "file_counts"}
    VectorStoreObjectFileCounts fileCounts;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata;
    # The Unix timestamp (in seconds) for when the vector store will expire
    @jsondata:Name {value: "expires_at"}
    int? expiresAt?;
    @jsondata:Name {value: "expires_after"}
    VectorStoreExpirationAfter expiresAfter?;
    # The Unix timestamp (in seconds) for when the vector store was last active
    @jsondata:Name {value: "last_active_at"}
    int? lastActiveAt;
    # The total number of bytes used by the files in the vector store
    @jsondata:Name {value: "usage_bytes"}
    int usageBytes;
    # The name of the vector store
    string name;
    # The Unix timestamp (in seconds) for when the vector store was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The identifier, which can be referenced in API endpoints
    string id;
    # The object type, which is always `vector_store`
    "vector_store" 'object;
    # The status of the vector store, which can be either `expired`, `in_progress`, or `completed`. A status of `completed` indicates that the vector store is ready for use
    "expired"|"in_progress"|"completed" status;
};

# The function definition
public type RunToolCallObjectFunction record {
    # The name of the function
    string name;
    # The arguments that the model expects you to pass to the function
    string arguments;
};

public type CreateCompletionRequest record {
    # Modify the likelihood of specified tokens appearing in the completion.
    # 
    # Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
    # 
    # As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated
    @jsondata:Name {value: "logit_bias"}
    record {|int...;|}? logitBias = {};
    # If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
    # 
    # Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend
    int? seed?;
    # The maximum number of [tokens](/tokenizer) that can be generated in the completion.
    # 
    # The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens
    @jsondata:Name {value: "max_tokens"}
    int? maxTokens = 16;
    # Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
    # 
    # [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
    @jsondata:Name {value: "presence_penalty"}
    decimal? presencePenalty = 0;
    # Echo back the prompt in addition to the completion
    boolean? echo = false;
    # The suffix that comes after a completion of inserted text.
    # 
    # This parameter is only supported for `gpt-3.5-turbo-instruct`
    string? suffix?;
    # How many completions to generate for each prompt.
    # 
    # **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`
    int? n = 1;
    # Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.
    # 
    # The maximum value for `logprobs` is 5
    int? logprobs?;
    # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
    # 
    # We generally recommend altering this or `temperature` but not both
    @jsondata:Name {value: "top_p"}
    decimal? topP = 1;
    # Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
    # 
    # [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
    @jsondata:Name {value: "frequency_penalty"}
    decimal? frequencyPenalty = 0;
    # Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.
    # 
    # When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return â€“ `best_of` must be greater than `n`.
    # 
    # **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`
    @jsondata:Name {value: "best_of"}
    int? bestOf = 1;
    # Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence
    string|string[]?? stop = ();
    # Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions)
    boolean? 'stream = false;
    # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
    # 
    # We generally recommend altering this or `top_p` but not both
    decimal? temperature = 1;
    # ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
    string|"gpt-3.5-turbo-instruct"|"davinci-002"|"babbage-002" model;
    @jsondata:Name {value: "stream_options"}
    ChatCompletionStreamOptions? streamOptions?;
    # The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.
    # 
    # Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document
    string|string[]|int[]|PromptItemsArray[]? prompt = "<|endoftext|>";
    # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
    string user?;
};

# Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint)
public type CreateCompletionResponse record {
    # The Unix timestamp (in seconds) of when the completion was created
    int created;
    CompletionUsage usage?;
    # The model used for completion
    string model;
    # A unique identifier for the completion
    string id;
    # The list of completion choices the model generated for the input prompt
    CreateCompletionResponseChoices[] choices;
    # This fingerprint represents the backend configuration that the model runs with.
    # 
    # Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism
    @jsondata:Name {value: "system_fingerprint"}
    string systemFingerprint?;
    # The object type, which is always "text_completion"
    "text_completion" 'object;
};

public type AssistantToolsFunction record {
    FunctionObject 'function;
    # The type of tool being defined: `function`
    "function" 'type;
};

# Log probability information for the choice
public type CreateChatCompletionResponseLogprobs record {
    # A list of message content tokens with log probability information
    ChatCompletionTokenLogprob[]? content;
};

public type PromptItemsArray int[];

# Controls for how a thread will be truncated prior to the run. Use this to control the intial context window of the run
public type TruncationObject record {
    # The number of most recent messages from the thread when constructing the context for the run
    @jsondata:Name {value: "last_messages"}
    int? lastMessages?;
    # The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`
    "auto"|"last_messages" 'type;
};

# Represents the Queries record for the operation: listVectorStores
public type ListVectorStoresQueries record {
    # A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
    string before?;
    # A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
    int 'limit = 20;
    # A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
    string after?;
    # Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
    "asc"|"desc" 'order = "desc";
};

# An object describing the expected output of the model. If `json_object` only `function` type `tools` are allowed to be passed to the Run. If `text` the model can return text or any value needed
public type AssistantsApiResponseFormat record {
    # Must be one of `text` or `json_object`
    "text"|"json_object" 'type = "text";
};

public type RunStepDetailsToolCallsObjectToolCalls RunStepDetailsToolCallsCodeObject|RunStepDetailsToolCallsFileSearchObject|RunStepDetailsToolCallsFunctionObject;

public type VectorStoreObjectFileCounts record {
    # The number of files that are currently being processed
    @jsondata:Name {value: "in_progress"}
    int inProgress;
    # The total number of files
    int total;
    # The number of files that were cancelled
    int cancelled;
    # The number of files that have been successfully processed
    int completed;
    # The number of files that have failed to process
    int failed;
};

public type ListMessagesResponse record {
    string 'object;
    MessageObject[] data;
    string? first_id;
    string? last_id;
    boolean has_more;
};

# An object specifying the format that the model must output. Compatible with [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.
# 
# Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.
# 
# **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length
public type CreateChatCompletionRequestResponseFormat record {
    # Must be one of `text` or `json_object`
    "text"|"json_object" 'type = "text";
};

# The hyperparameters used for the fine-tuning job. See the [fine-tuning guide](/docs/guides/fine-tuning) for more details
public type FineTuningJobHyperparameters record {
    # The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.
    # "auto" decides the optimal number of epochs based on the size of the dataset. If setting the number manually, we support any number between 1 and 50 epochs
    @jsondata:Name {value: "n_epochs"}
    "auto"|int nEpochs = "auto";
};

public type ChatCompletionNamedToolChoiceFunction record {
    # The name of the function to call
    string name;
};

public type ListAssistantsResponse record {
    @jsondata:Name {value: "first_id"}
    string firstId;
    AssistantObject[] data;
    @jsondata:Name {value: "last_id"}
    string lastId;
    @jsondata:Name {value: "has_more"}
    boolean hasMore;
    string 'object;
};

# A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
public type ThreadObjectToolResources record {
    @jsondata:Name {value: "code_interpreter"}
    CreateAssistantRequestToolResourcesCodeInterpreter codeInterpreter?;
    @jsondata:Name {value: "file_search"}
    ThreadObjectToolResourcesFileSearch fileSearch?;
};

public type InlineResponse2001 CreateTranslationResponseJson|CreateTranslationResponseVerboseJson;

# The text content that is part of a message
public type MessageRequestContentTextObject record {
    # Text content to be sent to the model
    string text;
    # Always `text`
    "text" 'type;
};

public type CreateThreadAndRunRequestTools AssistantToolsCode|AssistantToolsFileSearch|AssistantToolsFunction;

# Represents the Queries record for the operation: listRuns
public type ListRunsQueries record {
    # A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
    string before?;
    # A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
    int 'limit = 20;
    # A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
    string after?;
    # Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
    "asc"|"desc" 'order = "desc";
};

public type RunStepDetailsToolCallsCodeObjectCodeInterpreterOutputs RunStepDetailsToolCallsCodeOutputLogsObject|RunStepDetailsToolCallsCodeOutputImageObject;

# Represents a transcription response returned by model, based on the provided input
public type CreateTranscriptionResponseJson record {
    # The transcribed text
    string text;
};

# Usage statistics related to the run step. This value will be `null` while the run step's status is `in_progress`
public type RunStepCompletionUsage record {
    # Number of completion tokens used over the course of the run step
    @jsondata:Name {value: "completion_tokens"}
    int completionTokens;
    # Number of prompt tokens used over the course of the run step
    @jsondata:Name {value: "prompt_tokens"}
    int promptTokens;
    # Total number of tokens used (prompt + completion)
    @jsondata:Name {value: "total_tokens"}
    int totalTokens;
};

public type TranscriptionSegment record {
    # Start time of the segment in seconds
    float 'start;
    # Temperature parameter used for generating the segment
    float temperature;
    # Average logprob of the segment. If the value is lower than -1, consider the logprobs failed
    @jsondata:Name {value: "avg_logprob"}
    float avgLogprob;
    # Probability of no speech in the segment. If the value is higher than 1.0 and the `avg_logprob` is below -1, consider this segment silent
    @jsondata:Name {value: "no_speech_prob"}
    float noSpeechProb;
    # End time of the segment in seconds
    float end;
    # Array of token IDs for the text content
    int[] tokens;
    # Unique identifier of the segment
    int id;
    # Text content of the segment
    string text;
    # Seek offset of the segment
    int seek;
    # Compression ratio of the segment. If the value is greater than 2.4, consider the compression failed
    @jsondata:Name {value: "compression_ratio"}
    float compressionRatio;
};

public type DeleteVectorStoreFileResponse record {
    boolean deleted;
    string id;
    "vector_store.file.deleted" 'object;
};

# Represents the Headers record for the operation: getThread
public type GetThreadHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# Represents the Headers record for the operation: modifyRun
public type ModifyRunHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type CreateImageRequest record {
    # The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated
    @jsondata:Name {value: "response_format"}
    "url"|"b64_json"? responseFormat = "url";
    # The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3` models
    "256x256"|"512x512"|"1024x1024"|"1792x1024"|"1024x1792"? size = "1024x1024";
    # The model to use for image generation
    string|"dall-e-2"|"dall-e-3"? model = "dall-e-2";
    # The style of the generated images. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images. This param is only supported for `dall-e-3`
    "vivid"|"natural"? style = "vivid";
    # A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`
    string prompt;
    # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
    string user?;
    # The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported
    int? n = 1;
    # The quality of the image that will be generated. `hd` creates images with finer details and greater consistency across the image. This param is only supported for `dall-e-3`
    "standard"|"hd" quality = "standard";
};

public type BatchErrors record {
    BatchErrorsData[] data?;
    # The object type, which is always `list`
    string 'object?;
};

# `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools
public type ChatCompletionToolChoiceOptionOneOf1 "none"|"auto"|"required";

# Details on the tool outputs needed for this run to continue
public type RunObjectRequiredActionSubmitToolOutputs record {
    # A list of the relevant tool calls
    @jsondata:Name {value: "tool_calls"}
    RunToolCallObject[] toolCalls;
};

public type CreateTranscriptionRequest record {|
    # The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency
    @jsondata:Name {value: "timestamp_granularities[]"}
    ("word"|"segment")[] timestampGranularities = ["segment"];
    # The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm
    record {byte[] fileContent; string fileName;} file;
    # The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`
    @jsondata:Name {value: "response_format"}
    "json"|"text"|"srt"|"verbose_json"|"vtt" responseFormat = "json";
    # The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit
    decimal temperature = 0;
    # ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available
    string|"whisper-1" model;
    # The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency
    string language?;
    # An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language
    string prompt?;
|};

# Details on why the run is incomplete. Will be `null` if the run is not incomplete
public type RunObjectIncompleteDetails record {
    # The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run
    "max_completion_tokens"|"max_prompt_tokens" reason?;
};

public type MessageContentTextAnnotationsFileCitationObjectFileCitation record {
    # The ID of the specific File the citation is from
    @jsondata:Name {value: "file_id"}
    string fileId;
};

# Represents the Headers record for the operation: modifyAssistant
public type ModifyAssistantHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type SubmitToolOutputsRunRequestToolOutputs record {
    # The output of the tool call to be submitted to continue the run
    string output?;
    # The ID of the tool call in the `required_action` object within the run object the output is being submitted for
    @jsondata:Name {value: "tool_call_id"}
    string toolCallId?;
};

public type ListBatchesResponse record {
    @jsondata:Name {value: "first_id"}
    string firstId?;
    Batch[] data;
    @jsondata:Name {value: "last_id"}
    string lastId?;
    @jsondata:Name {value: "has_more"}
    boolean hasMore;
    "list" 'object;
};

public type CreateEmbeddingResponse record {
    # The list of embeddings generated by the model
    Embedding[] data;
    CreateEmbeddingResponseUsage usage;
    # The name of the model used to generate the embedding
    string model;
    # The object type, which is always "list"
    "list" 'object;
};

public type BatchErrorsData record {
    # An error code identifying the error type
    string code?;
    # The name of the parameter that caused the error, if applicable
    string? param?;
    # The line number of the input file where the error occurred, if applicable
    int? line?;
    # A human-readable message providing more details about the error
    string message?;
};

# A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
public type CreateThreadRequestToolResources record {
    @jsondata:Name {value: "code_interpreter"}
    CreateAssistantRequestToolResourcesCodeInterpreter codeInterpreter?;
    @jsondata:Name {value: "file_search"}
    CreateThreadRequestToolResourcesFileSearch fileSearch?;
};

# Represents the Queries record for the operation: listRunSteps
public type ListRunStepsQueries record {
    # A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
    string before?;
    # A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
    int 'limit = 20;
    # A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
    string after?;
    # Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
    "asc"|"desc" 'order = "desc";
};

# Represents an execution run on a [thread](/docs/api-reference/threads)
public type RunObject record {
    # The Unix timestamp (in seconds) for when the run was cancelled
    @jsondata:Name {value: "cancelled_at"}
    int? cancelledAt;
    # The instructions that the [assistant](/docs/api-reference/assistants) used for this run
    string instructions;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata;
    # The ID of the [assistant](/docs/api-reference/assistants) used for execution of this run
    @jsondata:Name {value: "assistant_id"}
    string assistantId;
    @jsondata:Name {value: "required_action"}
    RunObjectRequiredAction? requiredAction;
    RunCompletionUsage? usage;
    # The Unix timestamp (in seconds) for when the run was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The list of tools that the [assistant](/docs/api-reference/assistants) used for this run
    @constraint:Array {maxLength: 20}
    AssistantObjectTools[] tools = [];
    # The nucleus sampling value used for this run. If not set, defaults to 1
    @jsondata:Name {value: "top_p"}
    decimal? topP?;
    # The maximum number of completion tokens specified to have been used over the course of the run
    @jsondata:Name {value: "max_completion_tokens"}
    int? maxCompletionTokens;
    # The ID of the [thread](/docs/api-reference/threads) that was executed on as a part of this run
    @jsondata:Name {value: "thread_id"}
    string threadId;
    # The Unix timestamp (in seconds) for when the run will expire
    @jsondata:Name {value: "expires_at"}
    int? expiresAt;
    @jsondata:Name {value: "response_format"}
    AssistantsApiResponseFormatOption responseFormat;
    # The sampling temperature used for this run. If not set, defaults to 1
    decimal? temperature?;
    @jsondata:Name {value: "tool_choice"}
    AssistantsApiToolChoiceOption toolChoice;
    # The model that the [assistant](/docs/api-reference/assistants) used for this run
    string model;
    # The identifier, which can be referenced in API endpoints
    string id;
    @jsondata:Name {value: "last_error"}
    RunObjectLastError? lastError;
    @jsondata:Name {value: "incomplete_details"}
    RunObjectIncompleteDetails? incompleteDetails;
    @jsondata:Name {value: "truncation_strategy"}
    TruncationObject truncationStrategy;
    # The Unix timestamp (in seconds) for when the run was completed
    @jsondata:Name {value: "completed_at"}
    int? completedAt;
    @jsondata:Name {value: "parallel_tool_calls"}
    ParallelToolCalls parallelToolCalls;
    # The Unix timestamp (in seconds) for when the run was started
    @jsondata:Name {value: "started_at"}
    int? startedAt;
    # The Unix timestamp (in seconds) for when the run failed
    @jsondata:Name {value: "failed_at"}
    int? failedAt;
    # The maximum number of prompt tokens specified to have been used over the course of the run
    @jsondata:Name {value: "max_prompt_tokens"}
    int? maxPromptTokens;
    # The object type, which is always `thread.run`
    "thread.run" 'object;
    # The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`
    "queued"|"in_progress"|"requires_action"|"cancelling"|"cancelled"|"failed"|"completed"|"incomplete"|"expired" status;
};

public type ChatCompletionRequestUserMessage record {
    # The role of the messages author, in this case `user`
    "user" role;
    # An optional name for the participant. Provides the model information to differentiate between participants of the same role
    string name?;
    # The contents of the user message
    string|ChatCompletionRequestMessageContentPart[] content;
};

public type ModifyAssistantRequestToolResourcesCodeInterpreter record {
    # Overrides the list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
    @jsondata:Name {value: "file_ids"}
    string[] fileIds = [];
};

public type ChatCompletionTool record {
    FunctionObject 'function;
    # The type of the tool. Currently, only `function` is supported
    "function" 'type;
};

# Represents the Queries record for the operation: listFilesInVectorStoreBatch
public type ListFilesInVectorStoreBatchQueries record {
    # Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`
    "in_progress"|"completed"|"failed"|"cancelled" filter?;
    # A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
    string before?;
    # A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
    int 'limit = 20;
    # A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
    string after?;
    # Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
    "asc"|"desc" 'order = "desc";
};

# The expiration policy for a vector store
public type VectorStoreExpirationAfter record {
    # Anchor timestamp after which the expiration policy applies. Supported anchors: `last_active_at`
    "last_active_at" anchor;
    # The number of days after the anchor time that the vector store will expire
    @constraint:Int {minValue: 1, maxValue: 365}
    int days;
};

public type ModifyMessageRequest record {|
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
|};

# Controls which (if any) tool is called by the model.
# `none` means the model will not call any tools and instead generates a message.
# `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
# `required` means the model must call one or more tools before responding to the user.
# Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool
public type AssistantsApiToolChoiceOption AssistantsApiToolChoiceOptionOneOf1|AssistantsNamedToolChoice;

public type RunStepDetailsToolCallsCodeOutputImageObject record {
    RunStepDetailsToolCallsCodeOutputImageObjectImage image;
    # Always `image`
    "image" 'type;
};

# The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format. 
# 
# Omitting `parameters` defines a function with an empty parameter list
public type FunctionParameters record {
};

# The `File` object represents a document that has been uploaded to OpenAI
public type OpenAIFile record {
    # The file identifier, which can be referenced in the API endpoints.
    string id;
    # The size of the file, in bytes.
    int bytes;
    # The Unix timestamp (in seconds) for when the file was created.
    int created_at;
    # The name of the file.
    string filename;
    # The object type, which is always `file`.
    "file" 'object;
    # The intended purpose of the file. Supported values are `assistants`, `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results` and `vision`.
    "assistants"|"assistants_output"|"batch"|"batch_output"|"fine-tune"|"fine-tune-results"|"vision" purpose;
    # Deprecated. The current status of the file, which can be either `uploaded`, `processed`, or `error`.
    # 
    # # Deprecated
    @deprecated
    "uploaded"|"processed"|"error" status;
    # Deprecated. For details on why a fine-tuning training file failed validation, see the `error` field on `fine_tuning.job`.
    # 
    # # Deprecated
    @deprecated
    string status_details?;
};

# Represents the Queries record for the operation: listBatches
public type ListBatchesQueries record {
    # A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
    int 'limit = 20;
    # A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
    string after?;
};

public type ListVectorStoreFilesResponse record {
    string 'object;
    VectorStoreFileObject[] data;
    string first_id;
    string last_id;
    boolean has_more;
};

public type RunStepDetailsToolCallsCodeOutputImageObjectImage record {
    # The [file](/docs/api-reference/files) ID of the image
    @jsondata:Name {value: "file_id"}
    string fileId;
};

public type ChatCompletionRequestMessageContentPart ChatCompletionRequestMessageContentPartText|ChatCompletionRequestMessageContentPartImage;

public type Batch record {
    # The Unix timestamp (in seconds) for when the batch was cancelled
    @jsondata:Name {value: "cancelled_at"}
    int cancelledAt?;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    @jsondata:Name {value: "request_counts"}
    BatchRequestCounts requestCounts?;
    # The ID of the input file for the batch
    @jsondata:Name {value: "input_file_id"}
    string inputFileId;
    # The ID of the file containing the outputs of successfully executed requests
    @jsondata:Name {value: "output_file_id"}
    string outputFileId?;
    # The ID of the file containing the outputs of requests with errors
    @jsondata:Name {value: "error_file_id"}
    string errorFileId?;
    # The Unix timestamp (in seconds) for when the batch was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The Unix timestamp (in seconds) for when the batch started processing
    @jsondata:Name {value: "in_progress_at"}
    int inProgressAt?;
    # The Unix timestamp (in seconds) for when the batch expired
    @jsondata:Name {value: "expired_at"}
    int expiredAt?;
    # The Unix timestamp (in seconds) for when the batch started finalizing
    @jsondata:Name {value: "finalizing_at"}
    int finalizingAt?;
    # The Unix timestamp (in seconds) for when the batch was completed
    @jsondata:Name {value: "completed_at"}
    int completedAt?;
    # The OpenAI API endpoint used by the batch
    string endpoint;
    # The Unix timestamp (in seconds) for when the batch will expire
    @jsondata:Name {value: "expires_at"}
    int expiresAt?;
    # The Unix timestamp (in seconds) for when the batch started cancelling
    @jsondata:Name {value: "cancelling_at"}
    int cancellingAt?;
    # The time frame within which the batch should be processed
    @jsondata:Name {value: "completion_window"}
    string completionWindow;
    string id;
    # The Unix timestamp (in seconds) for when the batch failed
    @jsondata:Name {value: "failed_at"}
    int failedAt?;
    BatchErrors errors?;
    # The object type, which is always `batch`
    "batch" 'object;
    # The current status of the batch
    "validating"|"failed"|"in_progress"|"finalizing"|"completed"|"expired"|"cancelling"|"cancelled" status;
};

public type StaticChunkingStrategy record {|
    # The maximum number of tokens in each chunk. The default value is `800`. The minimum value is `100` and the maximum value is `4096`
    @jsondata:Name {value: "max_chunk_size_tokens"}
    int maxChunkSizeTokens;
    # The number of tokens that overlap between chunks. The default value is `400`.
    # 
    # Note that the overlap must not exceed half of `max_chunk_size_tokens`
    @jsondata:Name {value: "chunk_overlap_tokens"}
    int chunkOverlapTokens;
|};

public type CompleteUploadRequest record {|
    # The ordered list of Part IDs
    @jsondata:Name {value: "part_ids"}
    string[] partIds;
    # The optional md5 checksum for the file contents to verify if the bytes uploaded matches what you expect
    string md5?;
|};

public type AssistantObjectToolResourcesCodeInterpreter record {
    # A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool
    @jsondata:Name {value: "file_ids"}
    string[] fileIds = [];
};

# References an image [File](/docs/api-reference/files) in the content of a message
public type MessageContentImageFileObject record {
    @jsondata:Name {value: "image_file"}
    MessageContentImageFileObjectImageFile imageFile;
    # Always `image_file`
    "image_file" 'type;
};

public type ThreadObjectToolResourcesFileSearch record {
    # The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread
    @jsondata:Name {value: "vector_store_ids"}
    string[] vectorStoreIds?;
};

# Represents an `assistant` that can call the model and use tools
public type AssistantObject record {
    # The system instructions that the assistant uses. The maximum length is 256,000 characters
    string? instructions;
    @jsondata:Name {value: "tool_resources"}
    AssistantObjectToolResources? toolResources?;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata;
    # The Unix timestamp (in seconds) for when the assistant was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The description of the assistant. The maximum length is 512 characters
    string? description;
    # A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`
    @constraint:Array {maxLength: 128}
    AssistantObjectTools[] tools = [];
    # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
    # 
    # We generally recommend altering this or temperature but not both
    @jsondata:Name {value: "top_p"}
    decimal? topP = 1;
    @jsondata:Name {value: "response_format"}
    AssistantsApiResponseFormatOption responseFormat?;
    # The name of the assistant. The maximum length is 256 characters
    string? name;
    # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
    decimal? temperature = 1;
    # ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
    string model;
    # The identifier, which can be referenced in API endpoints
    string id;
    # The object type, which is always `assistant`
    "assistant" 'object;
};

@deprecated
public type ChatCompletionRequestFunctionMessage record {
    # The role of the messages author, in this case `function`
    "function" role;
    # The name of the function to call
    string name;
    # The contents of the function message
    string? content;
};

public type CreateFileRequest record {|
    # The File object (not file name) to be uploaded
    record {byte[] fileContent; string fileName;} file;
    # The intended purpose of the uploaded file.
    # 
    # Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning)
    "assistants"|"batch"|"fine-tune"|"vision" purpose;
|};

# The function that the model called
public type ChatCompletionMessageToolCallFunction record {
    # The name of the function to call
    string name;
    # The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function
    string arguments;
};

# A URL for the file that's generated when the assistant used the `code_interpreter` tool to generate a file
public type MessageContentTextAnnotationsFilePathObject record {
    @jsondata:Name {value: "file_path"}
    MessageContentTextAnnotationsFilePathObjectFilePath filePath;
    @jsondata:Name {value: "start_index"}
    int startIndex;
    @jsondata:Name {value: "end_index"}
    int endIndex;
    # The text in the message content that needs to be replaced
    string text;
    # Always `file_path`
    "file_path" 'type;
};

public type CreateThreadAndRunRequest record {|
    # Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis
    string? instructions?;
    @jsondata:Name {value: "tool_resources"}
    CreateThreadAndRunRequestToolResources? toolResources?;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    # The ID of the [assistant](/docs/api-reference/assistants) to use to execute this run
    @jsondata:Name {value: "assistant_id"}
    string assistantId;
    CreateThreadRequest thread?;
    # Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis
    CreateThreadAndRunRequestTools[]? tools?;
    @jsondata:Name {value: "truncation_strategy"}
    TruncationObject truncationStrategy?;
    # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
    # 
    # We generally recommend altering this or temperature but not both
    @jsondata:Name {value: "top_p"}
    decimal? topP = 1;
    # The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
    @jsondata:Name {value: "max_completion_tokens"}
    int? maxCompletionTokens?;
    @jsondata:Name {value: "response_format"}
    AssistantsApiResponseFormatOption responseFormat?;
    @jsondata:Name {value: "parallel_tool_calls"}
    ParallelToolCalls parallelToolCalls?;
    # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
    decimal? temperature = 1;
    @jsondata:Name {value: "tool_choice"}
    AssistantsApiToolChoiceOption toolChoice?;
    # The ID of the [Model](/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used
    string|"gpt-4o"|"gpt-4o-2024-05-13"|"gpt-4o-mini"|"gpt-4o-mini-2024-07-18"|"gpt-4-turbo"|"gpt-4-turbo-2024-04-09"|"gpt-4-0125-preview"|"gpt-4-turbo-preview"|"gpt-4-1106-preview"|"gpt-4-vision-preview"|"gpt-4"|"gpt-4-0314"|"gpt-4-0613"|"gpt-4-32k"|"gpt-4-32k-0314"|"gpt-4-32k-0613"|"gpt-3.5-turbo"|"gpt-3.5-turbo-16k"|"gpt-3.5-turbo-0613"|"gpt-3.5-turbo-1106"|"gpt-3.5-turbo-0125"|"gpt-3.5-turbo-16k-0613"? model?;
    # The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info
    @jsondata:Name {value: "max_prompt_tokens"}
    int? maxPromptTokens?;
|};

# Represents the Headers record for the operation: createAssistant
public type CreateAssistantHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# Fine-tuning job event object
public type FineTuningJobEvent record {
    "info"|"warn"|"error" level;
    @jsondata:Name {value: "created_at"}
    int createdAt;
    string id;
    string message;
    "fine_tuning.job.event" 'object;
};

# Represents the Headers record for the operation: listRuns
public type ListRunsHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# Specifies a tool the model should use. Use to force the model to call a specific tool
public type AssistantsNamedToolChoice record {
    ChatCompletionNamedToolChoiceFunction 'function?;
    # The type of the tool. If type is `function`, the function name must be set
    "function"|"code_interpreter"|"file_search" 'type;
};

public type ListRunStepsResponse record {
    string 'object;
    RunStepObject[] data;
    string? first_id;
    string? last_id;
    boolean has_more;
};

# Represents a message within a [thread](/docs/api-reference/threads)
public type MessageObject record {
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata;
    # The entity that produced the message. One of `user` or `assistant`
    "user"|"assistant" role;
    # If applicable, the ID of the [assistant](/docs/api-reference/assistants) that authored this message
    @jsondata:Name {value: "assistant_id"}
    string? assistantId;
    # The ID of the [run](/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints
    @jsondata:Name {value: "run_id"}
    string? runId;
    # A list of files attached to the message, and the tools they were added to
    MessageObjectAttachments[]? attachments?;
    # The Unix timestamp (in seconds) for when the message was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The content of the message in array of text and/or images
    MessageObjectContent[] content;
    # The Unix timestamp (in seconds) for when the message was completed
    @jsondata:Name {value: "completed_at"}
    int? completedAt?;
    # The [thread](/docs/api-reference/threads) ID that this message belongs to
    @jsondata:Name {value: "thread_id"}
    string threadId;
    # The identifier, which can be referenced in API endpoints
    string id;
    # The Unix timestamp (in seconds) for when the message was marked as incomplete
    @jsondata:Name {value: "incomplete_at"}
    int? incompleteAt?;
    @jsondata:Name {value: "incomplete_details"}
    MessageObjectIncompleteDetails? incompleteDetails?;
    # The object type, which is always `thread.message`
    "thread.message" 'object;
    # The status of the message, which can be either `in_progress`, `incomplete`, or `completed`
    "in_progress"|"incomplete"|"completed" status?;
};

public type CreateFineTuningJobRequest record {
    # The ID of an uploaded file that contains training data.
    # 
    # See [upload file](/docs/api-reference/files/create) for how to upload a file.
    # 
    # Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.
    # 
    # The contents of the file should differ depending on if the model uses the [chat](/docs/api-reference/fine-tuning/chat-input) or [completions](/docs/api-reference/fine-tuning/completions-input) format.
    # 
    # See the [fine-tuning guide](/docs/guides/fine-tuning) for more details
    @jsondata:Name {value: "training_file"}
    string trainingFile;
    # The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
    # If a seed is not specified, one will be generated for you
    int? seed?;
    # The ID of an uploaded file that contains validation data.
    # 
    # If you provide this file, the data is used to generate validation
    # metrics periodically during fine-tuning. These metrics can be viewed in
    # the fine-tuning results file.
    # The same data should not be present in both train and validation files.
    # 
    # Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.
    # 
    # See the [fine-tuning guide](/docs/guides/fine-tuning) for more details
    @jsondata:Name {value: "validation_file"}
    string? validationFile?;
    CreateFineTuningJobRequestHyperparameters hyperparameters?;
    # The name of the model to fine-tune. You can select one of the
    # [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned)
    string|"babbage-002"|"davinci-002"|"gpt-3.5-turbo" model;
    # A string of up to 18 characters that will be added to your fine-tuned model name.
    # 
    # For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`
    string? suffix?;
    # A list of integrations to enable for your fine-tuning job
    CreateFineTuningJobRequestIntegrations[]? integrations?;
};

public type MessageContentImageUrlObjectImageUrl record {
    # Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`
    "auto"|"low"|"high" detail = "auto";
    # The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp
    string url;
};

public type CreateFineTuningJobRequestIntegrations record {
    CreateFineTuningJobRequestWandb wandb;
    # The type of integration to enable. Currently, only "wandb" (Weights and Biases) is supported
    "wandb" 'type;
};

public type ChatCompletionTokenLogprob record {
    # List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number of requested `top_logprobs` returned
    @jsondata:Name {value: "top_logprobs"}
    ChatCompletionTokenLogprobTopLogprobs[] topLogprobs;
    # The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify that the token is very unlikely
    decimal logprob;
    # A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be `null` if there is no bytes representation for the token
    int[]? bytes;
    # The token
    string token;
};

# `auto` is the default value
public type AssistantsApiResponseFormatOptionOneOf1 "none"|"auto";

public type ChatCompletionRequestMessage ChatCompletionRequestSystemMessage|ChatCompletionRequestUserMessage|ChatCompletionRequestAssistantMessage|ChatCompletionRequestToolMessage|ChatCompletionRequestFunctionMessage;

# Represents the url or the content of an image generated by the OpenAI API
public type Image record {
    # The prompt that was used to generate the image, if there was any revision to the prompt
    @jsondata:Name {value: "revised_prompt"}
    string revisedPrompt?;
    # The base64-encoded JSON of the generated image, if `response_format` is `b64_json`
    @jsondata:Name {value: "b64_json"}
    string b64Json?;
    # The URL of the generated image, if `response_format` is `url` (default)
    string url?;
};

# Represents the Headers record for the operation: getAssistant
public type GetAssistantHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# Represents the Headers record for the operation: modifyThread
public type ModifyThreadHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# The hyperparameters used for the fine-tuning job
public type CreateFineTuningJobRequestHyperparameters record {
    # Number of examples in each batch. A larger batch size means that model parameters
    # are updated less frequently, but with lower variance
    @jsondata:Name {value: "batch_size"}
    "auto"|int batchSize = "auto";
    # The number of epochs to train the model for. An epoch refers to one full cycle
    # through the training dataset
    @jsondata:Name {value: "n_epochs"}
    "auto"|int nEpochs = "auto";
    # Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
    # overfitting
    @jsondata:Name {value: "learning_rate_multiplier"}
    "auto"|decimal learningRateMultiplier = "auto";
};

# The last error associated with this run. Will be `null` if there are no errors
public type RunObjectLastError record {
    # One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`
    "server_error"|"rate_limit_exceeded"|"invalid_prompt" code;
    # A human-readable description of the error
    string message;
};

# Represents a verbose json transcription response returned by model, based on the provided input
public type CreateTranscriptionResponseVerboseJson record {
    # The duration of the input audio
    string duration;
    # Extracted words and their corresponding timestamps
    TranscriptionWord[] words?;
    # The language of the input audio
    string language;
    # The transcribed text
    string text;
    # Segments of the transcribed text and their corresponding details
    TranscriptionSegment[] segments?;
};

public type CreateTranslationRequest record {|
    # The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm
    record {byte[] fileContent; string fileName;} file;
    # The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`
    @jsondata:Name {value: "response_format"}
    string responseFormat = "json";
    # The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit
    decimal temperature = 0;
    # ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available
    string|"whisper-1" model;
    # An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English
    string prompt?;
|};

public type UpdateVectorStoreRequest record {|
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    @jsondata:Name {value: "expires_after"}
    VectorStoreExpirationAfter expiresAfter?;
    # The name of the vector store
    string? name?;
|};

# The settings for your integration with Weights and Biases. This payload specifies the project that
# metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
# to your run, and set a default entity (team, username, etc) to be associated with your run
public type CreateFineTuningJobRequestWandb record {
    # A display name to set for the run. If not set, we will use the Job ID as the name
    string? name?;
    # The name of the project that the new run will be created under
    string project;
    # The entity to use for the run. This allows you to set the team or username of the WandB user that you would
    # like associated with the run. If not set, the default entity for the registered WandB API key is used
    string? entity?;
    # A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
    # default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}"
    string[] tags?;
};

@deprecated
public type ChatCompletionFunctions record {
    # The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64
    string name;
    # A description of what the function does, used by the model to choose when and how to call the function
    string description?;
    FunctionParameters parameters?;
};

public type AddUploadPartRequest record {|
    # The chunk of bytes for this Part
    record {byte[] fileContent; string fileName;} data;
|};

# The usage information for the request
public type CreateEmbeddingResponseUsage record {
    # The number of tokens used by the prompt
    @jsondata:Name {value: "prompt_tokens"}
    int promptTokens;
    # The total number of tokens used by the request
    @jsondata:Name {value: "total_tokens"}
    int totalTokens;
};

public type AssistantToolsCode record {
    # The type of tool being defined: `code_interpreter`
    "code_interpreter" 'type;
};

# This is returned when the chunking strategy is unknown. Typically, this is because the file was indexed before the `chunking_strategy` concept was introduced in the API
public type OtherChunkingStrategyResponseParam record {|
    # Always `other`
    "other" 'type;
|};

public type ChatCompletionRequestMessageContentPartImage record {
    @jsondata:Name {value: "image_url"}
    ChatCompletionRequestMessageContentPartImageImageUrl imageUrl;
    # The type of the content part
    "image_url" 'type;
};

public type AssistantObjectToolResourcesFileSearch record {
    # The ID of the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant
    @jsondata:Name {value: "vector_store_ids"}
    string[] vectorStoreIds?;
};

public type BatchesBody record {
    # The endpoint to be used for all requests in the batch. Currently `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch
    "/v1/chat/completions"|"/v1/embeddings"|"/v1/completions" endpoint;
    # Optional custom metadata for the batch
    record {|string...;|}? metadata?;
    # The ID of an uploaded file that contains requests for the new batch.
    # 
    # See [upload file](/docs/api-reference/files/create) for how to upload a file.
    # 
    # Your input file must be formatted as a [JSONL file](/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 100 MB in size
    @jsondata:Name {value: "input_file_id"}
    string inputFileId;
    # The time frame within which the batch should be processed. Currently only `24h` is supported
    @jsondata:Name {value: "completion_window"}
    "24h" completionWindow;
};

public type CreateVectorStoreFileBatchRequest record {|
    @jsondata:Name {value: "chunking_strategy"}
    ChunkingStrategyRequestParam chunkingStrategy?;
    # A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files
    @jsondata:Name {value: "file_ids"}
    string[] fileIds;
|};

# The Code Interpreter tool call definition
public type RunStepDetailsToolCallsCodeObjectCodeInterpreter record {
    # The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type
    RunStepDetailsToolCallsCodeObjectCodeInterpreterOutputs[] outputs;
    # The input to the Code Interpreter tool call
    string input;
};

public type CreateThreadRequest record {|
    @jsondata:Name {value: "tool_resources"}
    CreateThreadRequestToolResources? toolResources?;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    # A list of [messages](/docs/api-reference/messages) to start the thread with
    CreateMessageRequest[] messages?;
|};

public type ModifyAssistantRequestToolResourcesFileSearch record {
    # Overrides the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant
    @jsondata:Name {value: "vector_store_ids"}
    string[] vectorStoreIds?;
};

# On an incomplete message, details about why the message is incomplete
public type MessageObjectIncompleteDetails record {
    # The reason the message is incomplete
    "content_filter"|"max_tokens"|"run_cancelled"|"run_expired"|"run_failed" reason;
};

public type StaticChunkingStrategyRequestParam record {|
    StaticChunkingStrategy static;
    # Always `static`
    "static" 'type;
|};

# A list of files attached to a vector store
public type VectorStoreFileObject record {
    # The strategy used to chunk the file
    @jsondata:Name {value: "chunking_strategy"}
    StaticChunkingStrategyResponseParam|OtherChunkingStrategyResponseParam chunkingStrategy?;
    # The total vector store usage in bytes. Note that this may be different from the original file size
    @jsondata:Name {value: "usage_bytes"}
    int usageBytes;
    # The Unix timestamp (in seconds) for when the vector store file was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The identifier, which can be referenced in API endpoints
    string id;
    @jsondata:Name {value: "last_error"}
    VectorStoreFileObjectLastError? lastError;
    # The object type, which is always `vector_store.file`
    "vector_store.file" 'object;
    # The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to
    @jsondata:Name {value: "vector_store_id"}
    string vectorStoreId;
    # The status of the vector store file, which can be either `in_progress`, `completed`, `cancelled`, or `failed`. The status `completed` indicates that the vector store file is ready for use
    "in_progress"|"completed"|"cancelled"|"failed" status;
};

# Represents the Headers record for the operation: createRun
public type CreateRunHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type CreateThreadRequestToolResourcesFileSearch anydata;

# The Upload object can accept byte chunks in the form of Parts
public type Upload record {
    # The name of the file to be uploaded
    string filename;
    # The Unix timestamp (in seconds) for when the Upload was created
    @jsondata:Name {value: "expires_at"}
    int expiresAt;
    OpenAIFile file?;
    # The intended purpose of the file. [Please refer here](/docs/api-reference/files/object#files/object-purpose) for acceptable values
    string purpose;
    # The intended number of bytes to be uploaded
    int bytes;
    # The Unix timestamp (in seconds) for when the Upload was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The Upload unique identifier, which can be referenced in API endpoints
    string id;
    # The status of the Upload
    "pending"|"completed"|"cancelled"|"expired" status;
    # The object type, which is always "upload"
    "upload" 'object?;
};

# The last error associated with this vector store file. Will be `null` if there are no errors
public type VectorStoreFileObjectLastError record {
    # One of `server_error` or `rate_limit_exceeded`
    "internal_error"|"file_not_found"|"parsing_error"|"unhandled_mime_type" code;
    # A human-readable description of the error
    string message;
};

# For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure
public type FineTuningJobError record {
    # A machine-readable error code
    string code;
    # The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific
    string? param;
    # A human-readable error message
    string message;
};

# The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy
public type ChunkingStrategyRequestParam AutoChunkingStrategyRequestParam|StaticChunkingStrategyRequestParam;

# A list of the categories along with their scores as predicted by model
public type CreateModerationResponseCategoryScores record {
    # The score for the category 'self-harm/intent'
    @jsondata:Name {value: "self-harm/intent"}
    decimal selfHarmIntent;
    # The score for the category 'hate/threatening'
    @jsondata:Name {value: "hate/threatening"}
    decimal hateThreatening;
    # The score for the category 'self-harm/instructions'
    @jsondata:Name {value: "self-harm/instructions"}
    decimal selfHarmInstructions;
    # The score for the category 'sexual/minors'
    @jsondata:Name {value: "sexual/minors"}
    decimal sexualMinors;
    # The score for the category 'harassment/threatening'
    @jsondata:Name {value: "harassment/threatening"}
    decimal harassmentThreatening;
    # The score for the category 'hate'
    decimal hate;
    # The score for the category 'self-harm'
    @jsondata:Name {value: "self-harm"}
    decimal selfHarm;
    # The score for the category 'harassment'
    decimal harassment;
    # The score for the category 'sexual'
    decimal sexual;
    # The score for the category 'violence/graphic'
    @jsondata:Name {value: "violence/graphic"}
    decimal violenceGraphic;
    # The score for the category 'violence'
    decimal violence;
};

# Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.)
public type RunCompletionUsage record {
    # Number of completion tokens used over the course of the run
    @jsondata:Name {value: "completion_tokens"}
    int completionTokens;
    # Number of prompt tokens used over the course of the run
    @jsondata:Name {value: "prompt_tokens"}
    int promptTokens;
    # Total number of tokens used (prompt + completion)
    @jsondata:Name {value: "total_tokens"}
    int totalTokens;
};

# Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model
# 
# # Deprecated
@deprecated
public type ChatCompletionResponseMessageFunctionCall record {
    # The name of the function to call
    string name;
    # The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function
    string arguments;
};

# References an image URL in the content of a message
public type MessageContentImageUrlObject record {
    @jsondata:Name {value: "image_url"}
    MessageContentImageUrlObjectImageUrl imageUrl;
    # The type of the content part
    "image_url" 'type;
};

public type CreateCompletionResponseChoices record {
    # The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
    # `length` if the maximum number of tokens specified in the request was reached,
    # or `content_filter` if content was omitted due to a flag from our content filters
    @jsondata:Name {value: "finish_reason"}
    "stop"|"length"|"content_filter" finishReason;
    int index;
    string text;
    CreateCompletionResponseLogprobs? logprobs;
};

public type ImagesResponse record {
    int created;
    Image[] data;
};

public type DeleteModelResponse record {
    boolean deleted;
    string id;
    string 'object;
};

# Represents the Headers record for the operation: deleteThread
public type DeleteThreadHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type ChatCompletionMessageToolCall record {
    ChatCompletionMessageToolCallFunction 'function;
    # The ID of the tool call
    string id;
    # The type of the tool. Currently, only `function` is supported
    "function" 'type;
};

# Represents the Headers record for the operation: getRun
public type GetRunHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type VectorStoreFileBatchObjectFileCounts record {
    # The number of files that are currently being processed
    @jsondata:Name {value: "in_progress"}
    int inProgress;
    # The total number of files
    int total;
    # The number of files that where cancelled
    int cancelled;
    # The number of files that have been processed
    int completed;
    # The number of files that have failed to process
    int failed;
};

public type CreateImageEditRequest record {
    # The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not provided, image must have transparency, which will be used as the mask
    record {byte[] fileContent; string fileName;} image;
    # The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated
    @jsondata:Name {value: "response_format"}
    "url"|"b64_json"? responseFormat = "url";
    # The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`
    "256x256"|"512x512"|"1024x1024"? size = "1024x1024";
    # The model to use for image generation. Only `dall-e-2` is supported at this time
    string|"dall-e-2"? model = "dall-e-2";
    # A text description of the desired image(s). The maximum length is 1000 characters
    string prompt;
    # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
    string user?;
    # The number of images to generate. Must be between 1 and 10
    int? n = 1;
    # An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`
    record {byte[] fileContent; string fileName;} mask?;
};

# Overrides for the file search tool
public type AssistantToolsFileSearchFileSearch record {
    # The maximum number of results the file search tool should output. The default is 20 for gpt-4* models and 5 for gpt-3.5-turbo. This number should be between 1 and 50 inclusive.
    # 
    # Note that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](/docs/assistants/tools/file-search/number-of-chunks-returned) for more information
    @jsondata:Name {value: "max_num_results"}
    int maxNumResults?;
};

public type ListModelsResponse record {
    Model[] data;
    "list" 'object;
};

# Represents the Headers record for the operation: deleteAssistant
public type DeleteAssistantHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type AssistantObjectTools AssistantToolsCode|AssistantToolsFileSearch|AssistantToolsFunction;

# Describes an OpenAI model offering that can be used with the API
public type Model record {
    # The model identifier, which can be referenced in the API endpoints.
    string id;
    # The Unix timestamp (in seconds) when the model was created.
    int created;
    # The object type, which is always "model".
    "model" 'object;
    # The organization that owns the model.
    string owned_by;
};

public type ListFilesResponse record {
    OpenAIFile[] data;
    "list" 'object;
};

public type CreateVectorStoreRequest record {|
    # The chunking strategy used to chunk the file(s). If not set, will use the `auto` strategy. Only applicable if `file_ids` is non-empty
    @jsondata:Name {value: "chunking_strategy"}
    AutoChunkingStrategyRequestParam|StaticChunkingStrategyRequestParam chunkingStrategy?;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    @jsondata:Name {value: "expires_after"}
    VectorStoreExpirationAfter expiresAfter?;
    # A list of [File](/docs/api-reference/files) IDs that the vector store should use. Useful for tools like `file_search` that can access files
    @jsondata:Name {value: "file_ids"}
    string[] fileIds?;
    # The name of the vector store
    string name?;
|};

# Represents the Headers record for the operation: getRunStep
public type GetRunStepHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type CreateChatCompletionResponseChoices record {
    # The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
    # `length` if the maximum number of tokens specified in the request was reached,
    # `content_filter` if content was omitted due to a flag from our content filters,
    # `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function
    @jsondata:Name {value: "finish_reason"}
    "stop"|"length"|"tool_calls"|"content_filter"|"function_call" finishReason;
    # The index of the choice in the list of choices
    int index;
    ChatCompletionResponseMessage message;
    CreateChatCompletionResponseLogprobs? logprobs;
};

# Represents a thread that contains [messages](/docs/api-reference/messages)
public type ThreadObject record {
    @jsondata:Name {value: "tool_resources"}
    ThreadObjectToolResources? toolResources;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata;
    # The Unix timestamp (in seconds) for when the thread was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The identifier, which can be referenced in API endpoints
    string id;
    # The object type, which is always `thread`
    "thread" 'object;
};

# Options for streaming response. Only set this when you set `stream: true`
public type ChatCompletionStreamOptions record {
    # If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array. All other chunks will also include a `usage` field, but with a null value
    @jsondata:Name {value: "include_usage"}
    boolean includeUsage?;
};

# A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the "file_search" tool to search files
public type MessageContentTextAnnotationsFileCitationObject record {
    @jsondata:Name {value: "start_index"}
    int startIndex;
    @jsondata:Name {value: "file_citation"}
    MessageContentTextAnnotationsFileCitationObjectFileCitation fileCitation;
    @jsondata:Name {value: "end_index"}
    int endIndex;
    # The text in the message content that needs to be replaced
    string text;
    # Always `file_citation`
    "file_citation" 'type;
};

public type ListPaginatedFineTuningJobsResponse record {
    FineTuningJob[] data;
    @jsondata:Name {value: "has_more"}
    boolean hasMore;
    "list" 'object;
};

public type ModifyAssistantRequest record {|
    # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
    # 
    # We generally recommend altering this or temperature but not both
    @jsondata:Name {value: "top_p"}
    decimal? topP = 1;
    # The system instructions that the assistant uses. The maximum length is 256,000 characters
    string? instructions?;
    @jsondata:Name {value: "tool_resources"}
    ModifyAssistantRequestToolResources? toolResources?;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    @jsondata:Name {value: "response_format"}
    AssistantsApiResponseFormatOption responseFormat?;
    # The name of the assistant. The maximum length is 256 characters
    string? name?;
    # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
    decimal? temperature = 1;
    # The description of the assistant. The maximum length is 512 characters
    string? description?;
    # ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
    string model?;
    # A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`
    @constraint:Array {maxLength: 128}
    AssistantObjectTools[] tools = [];
|};

# Represents the Headers record for the operation: getMessage
public type GetMessageHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# Metrics at the step number during the fine-tuning job
public type FineTuningJobCheckpointMetrics record {
    @jsondata:Name {value: "full_valid_mean_token_accuracy"}
    decimal fullValidMeanTokenAccuracy?;
    @jsondata:Name {value: "valid_loss"}
    decimal validLoss?;
    @jsondata:Name {value: "full_valid_loss"}
    decimal fullValidLoss?;
    @jsondata:Name {value: "train_mean_token_accuracy"}
    decimal trainMeanTokenAccuracy?;
    @jsondata:Name {value: "valid_mean_token_accuracy"}
    decimal validMeanTokenAccuracy?;
    @jsondata:Name {value: "train_loss"}
    decimal trainLoss?;
    decimal step?;
};

public type MessageContentTextObjectTextAnnotations MessageContentTextAnnotationsFileCitationObject|MessageContentTextAnnotationsFilePathObject;

public type ChatCompletionRequestAssistantMessage record {
    # The role of the messages author, in this case `assistant`
    "assistant" role;
    @jsondata:Name {value: "function_call"}
    ChatCompletionRequestAssistantMessageFunctionCall? functionCall?;
    # An optional name for the participant. Provides the model information to differentiate between participants of the same role
    string name?;
    @jsondata:Name {value: "tool_calls"}
    ChatCompletionMessageToolCalls toolCalls?;
    # The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified
    string? content?;
};

# The last error associated with this run step. Will be `null` if there are no errors
public type RunStepObjectLastError record {
    # One of `server_error` or `rate_limit_exceeded`
    "server_error"|"rate_limit_exceeded" code;
    # A human-readable description of the error
    string message;
};

public type ListVectorStoresResponse record {
    string 'object;
    VectorStoreObject[] data;
    string first_id;
    string last_id;
    boolean has_more;
};

# Details of the Code Interpreter tool call the run step was involved in
public type RunStepDetailsToolCallsCodeObject record {
    @jsondata:Name {value: "code_interpreter"}
    RunStepDetailsToolCallsCodeObjectCodeInterpreter codeInterpreter;
    # The ID of the tool call
    string id;
    # The type of tool call. This is always going to be `code_interpreter` for this type of tool call
    "code_interpreter" 'type;
};

# Represents if a given text input is potentially harmful
public type CreateModerationResponse record {
    # The model used to generate the moderation results
    string model;
    # The unique identifier for the moderation request
    string id;
    # A list of moderation objects
    CreateModerationResponseResults[] results;
};

public type FineTuningIntegration record {
    CreateFineTuningJobRequestWandb wandb;
    # The type of the integration being enabled for the fine-tuning job
    "wandb" 'type;
};

public type SubmitToolOutputsRunRequest record {|
    # A list of tools for which the outputs are being submitted
    @jsondata:Name {value: "tool_outputs"}
    SubmitToolOutputsRunRequestToolOutputs[] toolOutputs;
|};

# A batch of files attached to a vector store
public type VectorStoreFileBatchObject record {
    @jsondata:Name {value: "file_counts"}
    VectorStoreFileBatchObjectFileCounts fileCounts;
    # The Unix timestamp (in seconds) for when the vector store files batch was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The identifier, which can be referenced in API endpoints
    string id;
    # The object type, which is always `vector_store.file_batch`
    "vector_store.files_batch" 'object;
    # The ID of the [vector store](/docs/api-reference/vector-stores/object) that the [File](/docs/api-reference/files) is attached to
    @jsondata:Name {value: "vector_store_id"}
    string vectorStoreId;
    # The status of the vector store files batch, which can be either `in_progress`, `completed`, `cancelled` or `failed`
    "in_progress"|"completed"|"cancelled"|"failed" status;
};

public type MessageContentTextAnnotationsFilePathObjectFilePath record {
    # The ID of the file that was generated
    @jsondata:Name {value: "file_id"}
    string fileId;
};

# A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
public type CreateThreadAndRunRequestToolResources record {
    @jsondata:Name {value: "code_interpreter"}
    CreateAssistantRequestToolResourcesCodeInterpreter codeInterpreter?;
    @jsondata:Name {value: "file_search"}
    AssistantObjectToolResourcesFileSearch fileSearch?;
};

public type ModifyRunRequest record {|
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
|};

# Specifying a particular function via `{"name": "my_function"}` forces the model to call that function
public type ChatCompletionFunctionCallOption record {
    # The name of the function to call
    string name;
};

# Represents the Headers record for the operation: listAssistants
public type ListAssistantsHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

# The `fine_tuning.job` object represents a fine-tuning job that has been created through the API
public type FineTuningJob record {
    # The file ID used for training. You can retrieve the training data with the [Files API](/docs/api-reference/files/retrieve-contents)
    @jsondata:Name {value: "training_file"}
    string trainingFile;
    # The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents)
    @jsondata:Name {value: "result_files"}
    string[] resultFiles;
    # The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running
    @jsondata:Name {value: "finished_at"}
    int? finishedAt;
    # The seed used for the fine-tuning job
    int seed;
    # The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running
    @jsondata:Name {value: "fine_tuned_model"}
    string? fineTunedModel;
    # The file ID used for validation. You can retrieve the validation results with the [Files API](/docs/api-reference/files/retrieve-contents)
    @jsondata:Name {value: "validation_file"}
    string? validationFile;
    # The Unix timestamp (in seconds) for when the fine-tuning job was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    FineTuningJobError? 'error;
    # The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running
    @jsondata:Name {value: "estimated_finish"}
    int? estimatedFinish?;
    # The organization that owns the fine-tuning job
    @jsondata:Name {value: "organization_id"}
    string organizationId;
    FineTuningJobHyperparameters hyperparameters;
    # The base model that is being fine-tuned
    string model;
    # The object identifier, which can be referenced in the API endpoints
    string id;
    # The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running
    @jsondata:Name {value: "trained_tokens"}
    int? trainedTokens;
    # A list of integrations to enable for this fine-tuning job
    FineTuningJobIntegrations[]? integrations?;
    # The object type, which is always "fine_tuning.job"
    "fine_tuning.job" 'object;
    # The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`
    "validating_files"|"queued"|"running"|"succeeded"|"failed"|"cancelled" status;
};

public type ChatCompletionRequestSystemMessage record {
    # The role of the messages author, in this case `system`
    "system" role;
    # An optional name for the participant. Provides the model information to differentiate between participants of the same role
    string name?;
    # The contents of the system message
    string content;
};

public type CreateTranslationResponseVerboseJson record {
    # The duration of the input audio
    string duration;
    # The language of the output translation (always `english`)
    string language;
    # The translated text
    string text;
    # Segments of the translated text and their corresponding details
    TranscriptionSegment[] segments?;
};

# Represents the Queries record for the operation: listAssistants
public type ListAssistantsQueries record {
    # A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list
    string before?;
    # A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20
    int 'limit = 20;
    # A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list
    string after?;
    # Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order
    "asc"|"desc" 'order = "desc";
};

public type MessageContentTextObjectText record {
    MessageContentTextObjectTextAnnotations[] annotations;
    # The data that makes up the text
    string value;
};

public type MessageObjectAttachments record {
    # The ID of the file to attach to the message
    @jsondata:Name {value: "file_id"}
    string fileId?;
    # The tools to add this file to
    MessageObjectTools[] tools?;
};

public type CreateCompletionResponseLogprobs record {
    @jsondata:Name {value: "top_logprobs"}
    record {||}[] topLogprobs?;
    @jsondata:Name {value: "token_logprobs"}
    decimal[] tokenLogprobs?;
    string[] tokens?;
    @jsondata:Name {value: "text_offset"}
    int[] textOffset?;
};

public type FineTuningJobIntegrations FineTuningIntegration;

public type DeleteFileResponse record {
    boolean deleted;
    string id;
    "file" 'object;
};

public type ListFineTuningJobEventsResponse record {
    FineTuningJobEvent[] data;
    "list" 'object;
};

# Represents the Headers record for the operation: cancelRun
public type CancelRunHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type CreateMessageRequest record {|
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    # The role of the entity that is creating the message. Allowed values include:
    # - `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
    # - `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation
    "user"|"assistant" role;
    # A list of files attached to the message, and the tools they should be added to
    MessageObjectAttachments[]? attachments?;
    string|(MessageContentImageFileObject|MessageContentImageUrlObject|MessageRequestContentTextObject)[] content;
|};

public type CreateAssistantRequestToolResourcesFileSearch anydata;

# Represents a step in execution of a run
public type RunStepObject record {
    # The Unix timestamp (in seconds) for when the run step was cancelled
    @jsondata:Name {value: "cancelled_at"}
    int? cancelledAt;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    # The ID of the [assistant](/docs/api-reference/assistants) associated with the run step
    @jsondata:Name {value: "assistant_id"}
    string assistantId;
    # The ID of the [run](/docs/api-reference/runs) that this run step is a part of
    @jsondata:Name {value: "run_id"}
    string runId;
    RunStepCompletionUsage? usage;
    # The Unix timestamp (in seconds) for when the run step was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired
    @jsondata:Name {value: "expired_at"}
    int? expiredAt?;
    # The type of run step, which can be either `message_creation` or `tool_calls`
    "message_creation"|"tool_calls" 'type;
    # The details of the run step
    @jsondata:Name {value: "step_details"}
    RunStepDetailsMessageCreationObject|RunStepDetailsToolCallsObject stepDetails;
    # The Unix timestamp (in seconds) for when the run step completed
    @jsondata:Name {value: "completed_at"}
    int? completedAt;
    # The ID of the [thread](/docs/api-reference/threads) that was run
    @jsondata:Name {value: "thread_id"}
    string threadId;
    # The identifier of the run step, which can be referenced in API endpoints
    string id;
    @jsondata:Name {value: "last_error"}
    RunStepObjectLastError? lastError;
    # The Unix timestamp (in seconds) for when the run step failed
    @jsondata:Name {value: "failed_at"}
    int? failedAt;
    # The object type, which is always `thread.run.step`
    "thread.run.step" 'object;
    # The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`
    "in_progress"|"cancelled"|"failed"|"completed"|"expired" status;
};

# Specifies a tool the model should use. Use to force the model to call a specific function
public type ChatCompletionNamedToolChoice record {
    ChatCompletionNamedToolChoiceFunction 'function;
    # The type of the tool. Currently, only `function` is supported
    "function" 'type;
};

public type CreateModerationResponseResults record {
    @jsondata:Name {value: "category_scores"}
    CreateModerationResponseCategoryScores categoryScores;
    # Whether any of the below categories are flagged
    boolean flagged;
    CreateModerationResponseCategories categories;
};

public type MessageObjectContent MessageContentImageFileObject|MessageContentImageUrlObject|MessageContentTextObject;

public type InlineResponse200 CreateTranscriptionResponseJson|CreateTranscriptionResponseVerboseJson;

# The definition of the function that was called
public type RunStepDetailsToolCallsFunctionObjectFunction record {
    # The output of the function. This will be `null` if the outputs have not been [submitted](/docs/api-reference/runs/submitToolOutputs) yet
    string? output;
    # The name of the function
    string name;
    # The arguments passed to the function
    string arguments;
};

public type FunctionObject record {
    # The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64
    string name;
    # A description of what the function does, used by the model to choose when and how to call the function
    string description?;
    FunctionParameters parameters?;
};

# Represents the Queries record for the operation: listFineTuningJobCheckpoints
public type ListFineTuningJobCheckpointsQueries record {
    # Number of checkpoints to retrieve
    int 'limit = 10;
    # Identifier for the last checkpoint ID from the previous pagination request
    string after?;
};

# A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs
public type CreateAssistantRequestToolResources record {
    @jsondata:Name {value: "code_interpreter"}
    CreateAssistantRequestToolResourcesCodeInterpreter codeInterpreter?;
    @jsondata:Name {value: "file_search"}
    CreateAssistantRequestToolResourcesFileSearch fileSearch?;
};

# Represents the Queries record for the operation: listFiles
public type ListFilesQueries record {
    # Only return files with the given purpose
    string purpose?;
};

public type CreateAssistantRequest record {|
    # An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
    # 
    # We generally recommend altering this or temperature but not both
    @jsondata:Name {value: "top_p"}
    decimal? topP = 1;
    # The system instructions that the assistant uses. The maximum length is 256,000 characters
    string? instructions?;
    @jsondata:Name {value: "tool_resources"}
    CreateAssistantRequestToolResources? toolResources?;
    # Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long
    record {}? metadata?;
    @jsondata:Name {value: "response_format"}
    AssistantsApiResponseFormatOption responseFormat?;
    # The name of the assistant. The maximum length is 256 characters
    string? name?;
    # What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic
    decimal? temperature = 1;
    # The description of the assistant. The maximum length is 512 characters
    string? description?;
    # ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them
    string|"gpt-4o"|"gpt-4o-2024-05-13"|"gpt-4o-mini"|"gpt-4o-mini-2024-07-18"|"gpt-4-turbo"|"gpt-4-turbo-2024-04-09"|"gpt-4-0125-preview"|"gpt-4-turbo-preview"|"gpt-4-1106-preview"|"gpt-4-vision-preview"|"gpt-4"|"gpt-4-0314"|"gpt-4-0613"|"gpt-4-32k"|"gpt-4-32k-0314"|"gpt-4-32k-0613"|"gpt-3.5-turbo"|"gpt-3.5-turbo-16k"|"gpt-3.5-turbo-0613"|"gpt-3.5-turbo-1106"|"gpt-3.5-turbo-0125"|"gpt-3.5-turbo-16k-0613" model;
    # A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`
    @constraint:Array {maxLength: 128}
    AssistantObjectTools[] tools = [];
|};

public type DeleteVectorStoreResponse record {
    boolean deleted;
    string id;
    "vector_store.deleted" 'object;
};

public type DeleteAssistantResponse record {
    boolean deleted;
    string id;
    "assistant.deleted" 'object;
};

public type CreateAssistantRequestToolResourcesCodeInterpreter record {
    # A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool
    @jsondata:Name {value: "file_ids"}
    string[] fileIds = [];
};

public type RunStepDetailsToolCallsFileSearchObject record {
    # For now, this is always going to be an empty object
    @jsondata:Name {value: "file_search"}
    record {} fileSearch;
    # The ID of the tool call object
    string id;
    # The type of tool call. This is always going to be `file_search` for this type of tool call
    "file_search" 'type;
};

# The upload Part represents a chunk of bytes we can add to an Upload object
public type UploadPart record {
    # The ID of the Upload object that this Part was added to
    @jsondata:Name {value: "upload_id"}
    string uploadId;
    # The Unix timestamp (in seconds) for when the Part was created
    @jsondata:Name {value: "created_at"}
    int createdAt;
    # The upload Part unique identifier, which can be referenced in API endpoints
    string id;
    # The object type, which is always `upload.part`
    "upload.part" 'object;
};

# Represents a chat completion response returned by model, based on the provided input
public type CreateChatCompletionResponse record {
    # The Unix timestamp (in seconds) of when the chat completion was created
    int created;
    CompletionUsage usage?;
    # The model used for the chat completion
    string model;
    # The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request
    @jsondata:Name {value: "service_tier"}
    "scale"|"default"? serviceTier?;
    # A unique identifier for the chat completion
    string id;
    # A list of chat completion choices. Can be more than one if `n` is greater than 1
    CreateChatCompletionResponseChoices[] choices;
    # This fingerprint represents the backend configuration that the model runs with.
    # 
    # Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism
    @jsondata:Name {value: "system_fingerprint"}
    string systemFingerprint?;
    # The object type, which is always `chat.completion`
    "chat.completion" 'object;
};

# Deprecated and replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model
# 
# # Deprecated
@deprecated
public type ChatCompletionRequestAssistantMessageFunctionCall record {
    # The name of the function to call
    string name;
    # The arguments to call the function with, as generated by the model in JSON format. Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema. Validate the arguments in your code before calling your function
    string arguments;
};

public type ChatCompletionRequestToolMessage record {
    # The role of the messages author, in this case `tool`
    "tool" role;
    # Tool call that this message is responding to
    @jsondata:Name {value: "tool_call_id"}
    string toolCallId;
    # The contents of the tool message
    string content;
};

public type CreateTranslationResponseJson record {
    string text;
};

public type ChatCompletionRequestMessageContentPartImageImageUrl record {
    # Specifies the detail level of the image. Learn more in the [Vision guide](/docs/guides/vision/low-or-high-fidelity-image-understanding)
    "auto"|"low"|"high" detail = "auto";
    # Either a URL of the image or the base64 encoded image data
    string url;
};

public type CreateImageVariationRequest record {
    # The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square
    record {byte[] fileContent; string fileName;} image;
    # The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated
    @jsondata:Name {value: "response_format"}
    "url"|"b64_json"? responseFormat = "url";
    # The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`
    "256x256"|"512x512"|"1024x1024"? size = "1024x1024";
    # The model to use for image generation. Only `dall-e-2` is supported at this time
    string|"dall-e-2"? model = "dall-e-2";
    # A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids)
    string user?;
    # The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported
    int? n = 1;
};

# A chat completion message generated by the model
public type ChatCompletionResponseMessage record {
    # The role of the author of this message
    "assistant" role;
    @jsondata:Name {value: "function_call"}
    ChatCompletionResponseMessageFunctionCall functionCall?;
    @jsondata:Name {value: "tool_calls"}
    ChatCompletionMessageToolCalls toolCalls?;
    # The contents of the message
    string? content;
};

public type DeleteThreadResponse record {
    boolean deleted;
    string id;
    "thread.deleted" 'object;
};

# Represents the Headers record for the operation: createThreadAndRun
public type CreateThreadAndRunHeaders record {
    @http:Header {name: "OpenAI-Beta"}
    string openAIBeta;
};

public type MessageObjectTools AssistantToolsCode|AssistantToolsFileSearchTypeOnly;

# Text output from the Code Interpreter tool call as part of a run step
public type RunStepDetailsToolCallsCodeOutputLogsObject record {
    # Always `logs`
    "logs" 'type;
    # The text output from the Code Interpreter tool call
    string logs;
};

public type StaticChunkingStrategyResponseParam record {|
    StaticChunkingStrategy static;
    # Always `static`
    "static" 'type;
|};

# Details of the message creation by the run step
public type RunStepDetailsMessageCreationObject record {
    @jsondata:Name {value: "message_creation"}
    RunStepDetailsMessageCreationObjectMessageCreation messageCreation;
    # Always `message_creation`
    "message_creation" 'type;
};

# Represents the Queries record for the operation: listPaginatedFineTuningJobs
public type ListPaginatedFineTuningJobsQueries record {
    # Number of fine-tuning jobs to retrieve
    int 'limit = 20;
    # Identifier for the last job from the previous pagination request
    string after?;
};

public type MessageContentImageFileObjectImageFile record {
    # The [File](/docs/api-reference/files) ID of the image in the message content. Set `purpose="vision"` when uploading the File if you need to later display the file content
    @jsondata:Name {value: "file_id"}
    string fileId;
    # Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`
    "auto"|"low"|"high" detail = "auto";
};
